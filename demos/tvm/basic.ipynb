{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm \n",
    "from tvm import relay\n",
    "from tvm.contrib import relay_viz, graph_executor\n",
    "import tvm.relay.testing.tf as tf_testing  \n",
    "\n",
    "import tensorflow as tf \n",
    "try:\n",
    "    tf_compat_v1 = tf.compat.v1\n",
    "except ImportError:\n",
    "    tf_compat_v1 = tf\n",
    "\n",
    "import onnx\n",
    "\n",
    "# import from tensorflow\n",
    "with tf_compat_v1.gfile.GFile(\"tf_model_path\", \"rb\") as f:\n",
    "    graph_def = tf_compat_v1.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    graph = tf.import_graph_def(graph_def, name=\"\")\n",
    "    \n",
    "    graph_def = tf_testing.ProcessGraphDefParam(graph_def) \n",
    "\n",
    "mod, params = relay.frontend.from_tensorflow(graph_def, layout=None) \n",
    "\n",
    "# import from onnx \n",
    "onnx_mod = onnx.load(\"onnx_model_path\")\n",
    "mod, params = relay.frontend.from_onnx(onnx_mod)\n",
    " \n",
    "# build and save to lib\n",
    "with tvm.transform.PassContext(opt_level = 1):\n",
    "    target = tvm.target.Target(\"llvm\", host=\"llvm\")\n",
    "    lib = relay.build(mod, target, params = params)\n",
    "    lib.export_library(\"lib_path\")\n",
    "\n",
    "# load from a lib\n",
    "lib = tvm.runtime.load_module(\"lib_path\")\n",
    "\n",
    "# run inference\n",
    "dev = tvm.cpu(0)\n",
    "m = graph_executor.GraphModule(lib[\"default\"](dev)) \n",
    "m.set_input(\"name\", tvm.nd.array([]))  \n",
    "m.run()  \n",
    "tvm_output = m.get_output(0)\n",
    "\n",
    "# visualize the relay tree \n",
    "viz = relay_viz.RelayVisualizer(mod)\n",
    "viz.render()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay \n",
    "from tvm.contrib import graph_executor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _get_func(shape, dtype):\n",
    "    a = relay.var(\"a\", shape=shape, dtype=dtype)\n",
    "    b = relay.var(\"b\", shape=shape, dtype=dtype) \n",
    "\n",
    "    zero = relay.const(0, \"int32\")\n",
    "    one = relay.const(1, \"float32\")\n",
    "\n",
    "    res = relay.qnn.op.add(a, b, one, zero, one, zero, one, zero)\n",
    "\n",
    "    return relay.Function([a, b], res)\n",
    "\n",
    "\n",
    "def _compile(func):\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = func\n",
    "\n",
    "    with tvm.transform.PassContext(3): \n",
    "        lib = relay.build(mod, \"llvm\", params={}) \n",
    "    return lib\n",
    "\n",
    "def _run(lib, a, b): \n",
    "    m = graph_executor.GraphModule(lib[\"default\"](tvm.cpu(0)))\n",
    "\n",
    "    m.set_input(\"a\", tvm.nd.array(a))\n",
    "    m.set_input(\"b\", tvm.nd.array(b)) \n",
    "\n",
    "    m.run() \n",
    "\n",
    "    output = m.get_output(0)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "a = np.random.randint(-128, 127, (1, 16), dtype=\"int16\")\n",
    "b = np.random.randint(-128, 127, (1, 16), dtype=\"int16\") \n",
    "\n",
    "func = _get_func((1, 16), \"int16\")\n",
    "\n",
    "lib = _compile(func)\n",
    "\n",
    "out = _run(lib, a, b)\n",
    "\n",
    "np.testing.assert_equal(a+b, out.numpy())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "import tvm.relay as relay\n",
    "from tvm.relay.dataflow_pattern import wildcard, is_op, rewrite, DFPatternCallback, FunctionPattern\n",
    "\n",
    "class TestCallback(DFPatternCallback):\n",
    "    def __init__(self):\n",
    "        super(TestCallback, self).__init__()\n",
    "        self.x = wildcard()\n",
    "        self.y = wildcard()\n",
    "\n",
    "        pattern = is_op('add')(self.x, self.y)\n",
    "        pattern = FunctionPattern([wildcard(), wildcard()], pattern)(wildcard(), wildcard())\n",
    "        self.pattern = pattern\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        print('here')\n",
    "        x = node_map[self.x][0]\n",
    "        y = node_map[self.y][0]\n",
    "        return x - y\n",
    "\n",
    "class TestCallback2(DFPatternCallback):\n",
    "    def __init__(self):\n",
    "        super(TestCallback2, self).__init__()\n",
    "        self.x = wildcard()\n",
    "        self.y = wildcard()\n",
    "\n",
    "        pattern = is_op('add')(self.x, self.y)\n",
    "        # pattern = FunctionPattern([wildcard(), wildcard()], pattern)(wildcard(), wildcard())\n",
    "        self.pattern = pattern\n",
    "\n",
    "    def callback(self, pre, post, node_map):\n",
    "        print('here')\n",
    "        x = node_map[self.x][0]\n",
    "        y = node_map[self.y][0]\n",
    "        return x - y\n",
    "x = relay.var('x')\n",
    "y = relay.var('y')\n",
    "z = relay.var('z')\n",
    "expr = (x + y) * z\n",
    "\n",
    "p = wildcard() + wildcard()\n",
    "fp = FunctionPattern([wildcard(), wildcard()], p)\n",
    "\n",
    "print(\"EXPR: =====\\n\",expr)\n",
    "\n",
    "expr_p = p.partition(expr)\n",
    "print(\"EXPR_p: =====\\n\",expr_p)\n",
    "\n",
    "expr_r = rewrite(TestCallback(), expr_p)\n",
    "print(\"EXPR_r: =====\\n\",expr_r)\n",
    "\n",
    "ee = rewrite(TestCallback2(), expr)\n",
    "print(\"EXPR_r2:=====\\n\",ee)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traverse Relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_relay(ir_mod):\n",
    "    global_vars = ir_mod.get_global_vars()\n",
    "    graph_names = [] \n",
    "    for gv_node in global_vars:\n",
    "        if gv_node.name_hint == \"main\":\n",
    "            graph_names.insert(0, gv_node.name_hint)\n",
    "        else:\n",
    "            graph_names.append(gv_node.name_hint)\n",
    "\n",
    "    node_to_id = {} \n",
    "    node_count_offset = 0 \n",
    "\n",
    "    def traverse_expr(node): \n",
    "        optype = \"\" \n",
    "        \n",
    "        if isinstance(node,relay.expr.Call): \n",
    "            args = [ arg.handle.value for arg in node.args] \n",
    "            if isinstance(node.op,tvm.ir.op.Op):\n",
    "                optype = node.op.name\n",
    "                name = optype + \"_\" + str(node.handle.value)[-4:]\n",
    "            elif isinstance(node.op,tvm.ir.expr.GlobalVar):  \n",
    "                name = node.op.name_hint.replace(\"tvmgen_default_versal_aie_main\", \"AIE\")\n",
    "                optype = \"GVar\"\n",
    "            elif isinstance(node.op,relay.function.Function): \n",
    "                optype = \"subgraph\"\n",
    "                name = \"Func_\" + str(node.handle.value)[-4:] \n",
    "            else:\n",
    "                print(\"xxxxx\",node)\n",
    "            shape = node.checked_type if hasattr(node, \"checked_type\") else \"\" \n",
    "        elif isinstance(node,relay.expr.Var):\n",
    "            if g != \"main\":\n",
    "                return\n",
    "            shape = node.checked_type if hasattr(node, \"checked_type\") else \"\" \n",
    "            node_to_id[node.handle.value] = {\n",
    "                \"args\":[], \"name\":node.name_hint,\"shape\":shape,\"optype\":\"Placeholder\"\n",
    "            } \n",
    "        elif isinstance(node,relay.expr.Tuple): \n",
    "            # shape = node.checked_type if hasattr(node, \"checked_type\") else \"\" \n",
    "            args = [ f.handle.value for f in node.fields]\n",
    "            name = \"tuple_\" + str(node.handle.value)[-4:]\n",
    "            shape = \"\"\n",
    "            optype = \"Concat\"\n",
    "        elif isinstance(node,relay.function.Function):\n",
    "            print(node.astext())   \n",
    "    \n",
    "\n",
    "    for name in graph_names:\n",
    "        node_count_offset += len(node_to_id)\n",
    "        # node_to_id.clear()  \n",
    "        relay.analysis.post_order_visit(ir_mod[name], traverse_expr)\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tvm\n",
    "from tvm import te \n",
    "from tvm.driver.build_module import get_binds\n",
    "\n",
    "def sch2stmt(sch):\n",
    "    sch = sch.normalize()\n",
    "    infer_bounds = tvm.te.schedule.InferBound(sch) \n",
    "    stmt = tvm.te.schedule.ScheduleOps(sch, infer_bounds, False)\n",
    " \n",
    "\n",
    "    return stmt\n",
    "\n",
    "def stmt2primfunc(stmt, args):\n",
    "    compact = tvm.te.schedule.VerifyCompactBuffer(stmt)\n",
    "    binds, arg_list = get_binds(args, compact, None)\n",
    "    func = tvm.te.schedule.SchedulePostProcToPrimFunc(arg_list, stmt, binds)\n",
    "    return func\n",
    "\n",
    "\n",
    "def test():\n",
    "    m = te.size_var(\"m\")\n",
    "    n = te.size_var(\"n\")\n",
    "    m = te.const(32)\n",
    "    n = te.const(64)\n",
    "    A = te.placeholder((m, n), name=\"A\")\n",
    "    T = te.compute((m, n), lambda i, j: A[i, j])\n",
    "\n",
    "    s = te.create_schedule(T.op)\n",
    "    xo, yo, xi, yi = s[T].tile(T.op.axis[0], T.op.axis[1], x_factor=10, y_factor=5)\n",
    "\n",
    "    stmt = sch2stmt(s)\n",
    "    func = stmt2primfunc(stmt, [A])\n",
    "    print(func)\n",
    "\n",
    "    print('='*20)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile\n",
    "\n",
    "\n",
    "# fuse\n",
    "\n",
    "# split\n",
    "\n",
    "# reorder\n",
    "\n",
    "# vectorize\n",
    "\n",
    "# ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.instrument.pass_instrument\n",
    "class PrintIR:\n",
    "    \"\"\"Print the name of the pass, the IR\"\"\"\n",
    "\n",
    "    def run_before_pass(self, mod, info):\n",
    "        pass\n",
    "        # print(\"Running pass: \", info.name)\n",
    "        # if info.name == \"LowerTensorExpr\":\n",
    "        #     print(\"Final Relay IR:\")\n",
    "        #     print(mod.astext(show_meta_data=False))\n",
    "\n",
    "    def run_after_pass(self, mod, info):\n",
    "        print(\"=\" * 20, info.name)\n",
    "        if \"SomeText\" in info.name:\n",
    "            print(\"=\" * 20, info.name)\n",
    "            print(mod.astext(show_meta_data=False))\n",
    "\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3,config={},instruments=[PrintIR()],): \n",
    "    lib = relay.build(mod, \"llvm\", params={}) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3dddbb0b275db9de04c7d27e87a94e8b852bbcb7f5882ec85965e27d300cec6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
